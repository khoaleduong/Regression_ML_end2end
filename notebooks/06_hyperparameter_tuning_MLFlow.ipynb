{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5076c775",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93458fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import mlflow\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e37cfc",
   "metadata": {},
   "source": [
    "## 2. Load processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a015bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/leduongkhoa/Regression_MachineLearning_End2End/data/processed/encoded_train.csv\")\n",
    "eval_df = pd.read_csv(\"/Users/leduongkhoa/Regression_MachineLearning_End2End/data/processed/encoded_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531ba665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (578878, 39) (578878,)\n",
      "Eval shape:  (148697, 39) (148697,)\n"
     ]
    }
   ],
   "source": [
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape: \", X_train.shape, y_train.shape)\n",
    "print(\"Eval shape: \", X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61941e",
   "metadata": {},
   "source": [
    "## 3. Define Optuna objective function and MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6311ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\"\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_eval)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_eval, y_pred))\n",
    "        r2 = float(r2_score(y_eval, y_pred))\n",
    "\n",
    "        # log parameters and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8604c",
   "metadata": {},
   "source": [
    "## 4. Run Optuna with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b69d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/05 21:25:50 INFO mlflow.tracking.fluent: Experiment with name 'XGBoost_Hyperparameter_Tuning' does not exist. Creating a new experiment.\n",
      "\u001b[32m[I 2026-02-05 21:25:50,500]\u001b[0m A new study created in memory with name: XGBoost_Hyperparameter_Tuning\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:26:05,640]\u001b[0m Trial 0 finished with value: 83366.14424146038 and parameters: {'n_estimators': 440, 'max_depth': 5, 'learning_rate': 0.010635112726326936, 'subsample': 0.5976154599632177, 'colsample_bytree': 0.8566501889270856, 'min_child_weight': 5, 'gamma': 4.354451368269224, 'reg_alpha': 0.36546550061165844, 'reg_lambda': 1.1218879006531735e-05}. Best is trial 0 with value: 83366.14424146038.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:26:40,190]\u001b[0m Trial 1 finished with value: 67663.46003956138 and parameters: {'n_estimators': 751, 'max_depth': 8, 'learning_rate': 0.05404603338274638, 'subsample': 0.8722726049026706, 'colsample_bytree': 0.5605552743117814, 'min_child_weight': 6, 'gamma': 2.8159792714428677, 'reg_alpha': 0.0037382843477239635, 'reg_lambda': 0.00034726652678945043}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:26:59,063]\u001b[0m Trial 2 finished with value: 74666.3256135504 and parameters: {'n_estimators': 762, 'max_depth': 4, 'learning_rate': 0.0438015546206476, 'subsample': 0.5905618836737885, 'colsample_bytree': 0.667685007374361, 'min_child_weight': 1, 'gamma': 3.064365391467609, 'reg_alpha': 2.4422040668028296e-05, 'reg_lambda': 0.0005275664379141454}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:27:23,539]\u001b[0m Trial 3 finished with value: 70046.35426472196 and parameters: {'n_estimators': 754, 'max_depth': 6, 'learning_rate': 0.10678401474954072, 'subsample': 0.7845062551036792, 'colsample_bytree': 0.6959405076944383, 'min_child_weight': 10, 'gamma': 1.6568934758733889, 'reg_alpha': 0.2784299398599257, 'reg_lambda': 0.0008743055044844766}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:27:40,734]\u001b[0m Trial 4 finished with value: 69508.17120438299 and parameters: {'n_estimators': 312, 'max_depth': 8, 'learning_rate': 0.07712549349949187, 'subsample': 0.9674324596120043, 'colsample_bytree': 0.8193338439350405, 'min_child_weight': 4, 'gamma': 2.0223325702215322, 'reg_alpha': 1.6547851024451392, 'reg_lambda': 1.4021632460653624e-08}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:27:50,419]\u001b[0m Trial 5 finished with value: 77262.33841777027 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.19268580875534055, 'subsample': 0.9253601967912257, 'colsample_bytree': 0.9517131503774592, 'min_child_weight': 1, 'gamma': 0.040609441394336976, 'reg_alpha': 0.001102636587050683, 'reg_lambda': 0.00013429167477251454}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:28:24,717]\u001b[0m Trial 6 finished with value: 73278.07464816156 and parameters: {'n_estimators': 634, 'max_depth': 8, 'learning_rate': 0.010065566175117805, 'subsample': 0.8008710016010651, 'colsample_bytree': 0.8767098093519339, 'min_child_weight': 3, 'gamma': 3.657491348737076, 'reg_alpha': 2.919885163704207e-05, 'reg_lambda': 0.08955320082962895}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:28:36,220]\u001b[0m Trial 7 finished with value: 71798.96304813458 and parameters: {'n_estimators': 380, 'max_depth': 5, 'learning_rate': 0.06545672756938889, 'subsample': 0.7576832299706906, 'colsample_bytree': 0.6120261597827452, 'min_child_weight': 4, 'gamma': 4.847264802643386, 'reg_alpha': 2.3341719695693056e-06, 'reg_lambda': 0.01306394804490785}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:29:00,316]\u001b[0m Trial 8 finished with value: 77360.78059575634 and parameters: {'n_estimators': 927, 'max_depth': 5, 'learning_rate': 0.18512751264977456, 'subsample': 0.6630826998932453, 'colsample_bytree': 0.9465024867967624, 'min_child_weight': 4, 'gamma': 2.1450689837448262, 'reg_alpha': 0.00016894236363654654, 'reg_lambda': 0.0003522782983763181}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:29:26,739]\u001b[0m Trial 9 finished with value: 75824.21443970344 and parameters: {'n_estimators': 640, 'max_depth': 6, 'learning_rate': 0.013912634841645516, 'subsample': 0.7689175322270594, 'colsample_bytree': 0.8640381603857112, 'min_child_weight': 1, 'gamma': 2.214327181143065, 'reg_alpha': 0.35464452712310934, 'reg_lambda': 2.885301503339348e-07}. Best is trial 1 with value: 67663.46003956138.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:30:29,781]\u001b[0m Trial 10 finished with value: 67279.99510774249 and parameters: {'n_estimators': 956, 'max_depth': 10, 'learning_rate': 0.028848038574919403, 'subsample': 0.873003905513015, 'colsample_bytree': 0.5113716898706556, 'min_child_weight': 8, 'gamma': 0.9063370927419108, 'reg_alpha': 8.598358848672926e-08, 'reg_lambda': 4.272509215571642}. Best is trial 10 with value: 67279.99510774249.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:31:36,606]\u001b[0m Trial 11 finished with value: 67030.71156707843 and parameters: {'n_estimators': 996, 'max_depth': 10, 'learning_rate': 0.028310362529526935, 'subsample': 0.8928352731168709, 'colsample_bytree': 0.5052593737039531, 'min_child_weight': 8, 'gamma': 0.751548299603698, 'reg_alpha': 5.307817810496198e-08, 'reg_lambda': 7.5453068305914215}. Best is trial 11 with value: 67030.71156707843.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 21:32:52,485]\u001b[0m Trial 12 finished with value: 67068.56780000583 and parameters: {'n_estimators': 990, 'max_depth': 10, 'learning_rate': 0.025490974379130067, 'subsample': 0.8901155017533505, 'colsample_bytree': 0.520369797510156, 'min_child_weight': 8, 'gamma': 0.6439689250328752, 'reg_alpha': 1.0960509005874511e-08, 'reg_lambda': 9.66812180987395}. Best is trial 11 with value: 67030.71156707843.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 22:50:23,606]\u001b[0m Trial 13 finished with value: 67357.37625255801 and parameters: {'n_estimators': 996, 'max_depth': 10, 'learning_rate': 0.0235978266726878, 'subsample': 0.998688644961696, 'colsample_bytree': 0.5233267623432947, 'min_child_weight': 8, 'gamma': 0.10225811341782176, 'reg_alpha': 1.0527842452641645e-08, 'reg_lambda': 9.636407404986873}. Best is trial 11 with value: 67030.71156707843.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 22:51:13,351]\u001b[0m Trial 14 finished with value: 68419.28784363242 and parameters: {'n_estimators': 846, 'max_depth': 9, 'learning_rate': 0.023324061197068445, 'subsample': 0.8744544506739239, 'colsample_bytree': 0.6138787974635128, 'min_child_weight': 8, 'gamma': 1.0155702859185385, 'reg_alpha': 3.9115177618202377e-07, 'reg_lambda': 0.13822310028533324}. Best is trial 11 with value: 67030.71156707843.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 996, 'max_depth': 10, 'learning_rate': 0.028310362529526935, 'subsample': 0.8928352731168709, 'colsample_bytree': 0.5052593737039531, 'min_child_weight': 8, 'gamma': 0.751548299603698, 'reg_alpha': 5.307817810496198e-08, 'reg_lambda': 7.5453068305914215}\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"/Users/leduongkhoa/Regression_MachineLearning_End2End/mlruns\")\n",
    "mlflow.set_experiment(\"XGBoost_Hyperparameter_Tuning\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"XGBoost_Hyperparameter_Tuning\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(f\"Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543fe3b",
   "metadata": {},
   "source": [
    "## 5. Train the model with the best params and log into MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b825080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 22:52:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Performance on Eval Set:\n",
      "RMSE: 68632.15363535204\n",
      "MAE: 30543.184797070266\n",
      "R2: 0.9635907364673416\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))\n",
    "mae = float(mean_absolute_error(y_eval, y_pred))\n",
    "r2 = float(r2_score(y_eval, y_pred))\n",
    "\n",
    "print(f\"Best Model Performance on Eval Set:\\nRMSE: {rmse}\\nMAE: {mae}\\nR2: {r2}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Best_XGBoost_Model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, artifact_path=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
